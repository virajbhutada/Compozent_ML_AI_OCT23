{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOfI+tihJIEpdjpp/3VJ/l9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/virajbhutada/Compozent_ML_AI_OCT23/blob/main/Task1_(BASIC)_Spam_Email_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ML and AI Intern @Compozent OCT23\n",
        "\n",
        "# Author: Viraj N. Bhutada\n",
        "\n",
        "# **TASK 1 (BASIC): Spam Email Classifier**\n",
        "\n",
        "\n",
        "# Overview:    \n",
        "- In this project, I created a smart tool to spot those annoying spam emails we all receive. Imagine it like a virtual guard for your inbox! Using a clever technique called the Naive Bayes algorithm, my creation learned from examples and correctly identified 95% of the emails in our test collection (accuracy score: 0.95).\n",
        "- This accomplishment shows that it's really good at telling which emails are useful and which ones are just clutter. It's like having a reliable assistant who sifts through your emails, ensuring you only see the important stuff.\n",
        "\n",
        "\n",
        "\n",
        "# About the Dataset:\n",
        "- The dataset we are using contains information about 5172 randomly selected email files and their corresponding labels for spam or not-spam classification. The dataset is provided in a CSV file format, making it convenient for analysis and modeling.\n",
        "\n",
        "- Dataset Details:\n",
        "https://www.kaggle.com/datasets/balaka18/email-spam-classification-dataset-csv\n",
        "\n",
        " Rows: 5172 (Each row represents a single email)\n",
        "Columns: 3002 (1 column for email name, 3000 columns for the most common words, and 1 column for labels)\n",
        "Labeling: The first column indicates the email name (anonymized for privacy) and the last column contains the labels: 1 for spam and 0 for not spam. The 3000 columns in between represent the 3000 most common words found in the emails, excluding non-alphabetical characters or words.\n",
        "To access the dataset, you can visit the following link: Email Spam Classification Dataset (emails.csv)\n",
        "\n",
        "#  Project Steps:\n",
        "1. Data Loading and Exploration\n",
        "Load the dataset and explore its structure. Understand the columns, the features, and the labels. Familiarize yourself with the dataset's format.\n",
        "\n",
        "2. Data Preprocessing\n",
        "Handle any missing values and prepare the data for training. In this project, missing values were imputed using mean values for each feature.\n",
        "\n",
        "3. Model Building\n",
        "Implement a machine learning model using the Naive Bayes algorithm (MultinomialNB) for text classification. Train the model using the preprocessed data.\n",
        "\n",
        "4. Model Evaluation\n",
        "Evaluate the trained model using various metrics, including accuracy, precision, recall, and F1-score. Understand how well the model performs in classifying emails as spam or not spam.\n",
        "\n",
        "5. Interpretation of Results\n",
        "Interpret the results obtained, especially focusing on the accuracy score. Accuracy of 0.95 means that the model correctly predicted 95% of the emails in the test dataset. It signifies the model's effectiveness in distinguishing between spam and non-spam emails.\n",
        "\n",
        "6. Drawing Insights from Results, With an accuracy score of 95%, the model accurately classified emails, showcasing its efficiency in spam detection. This outcome reinforces its practicality for real-world email filtering challenges.\n"
      ],
      "metadata": {
        "id": "dWo9gtwDbTrp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 1: Import Libraries**"
      ],
      "metadata": {
        "id": "7kCHVpSYYads"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.impute import SimpleImputer\n"
      ],
      "metadata": {
        "id": "ar0pzIDSWn3d"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 2: Load and Explore the Data**"
      ],
      "metadata": {
        "id": "kSw271tlYdmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset with individual words as columns\n",
        "data = pd.read_csv('emails.csv')\n",
        "\n",
        "# Assuming 'Prediction' column contains the labels (1 for spam, 0 for not spam)\n",
        "X = data.drop(columns=['Email No.', 'Prediction'])  # Features\n",
        "y = data['Prediction']  # Labels\n",
        "\n",
        "# Explore the data\n",
        "print(data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jM4dUWgXWpHE",
        "outputId": "875503de-6295-4411-bed9-ee989ae4fcc2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Email No.  the  to  ect  and  for  of    a  you  hou  ...  connevey  jay  \\\n",
            "0   Email 1    0   0    1    0    0   0    2    0    0  ...         0    0   \n",
            "1   Email 2    8  13   24    6    6   2  102    1   27  ...         0    0   \n",
            "2   Email 3    0   0    1    0    0   0    8    0    0  ...         0    0   \n",
            "3   Email 4    0   5   22    0    5   1   51    2   10  ...         0    0   \n",
            "4   Email 5    7   6   17    1    5   2   57    0    9  ...         0    0   \n",
            "\n",
            "   valued  lay  infrastructure  military  allowing  ff  dry  Prediction  \n",
            "0       0    0               0         0         0   0    0           0  \n",
            "1       0    0               0         0         0   1    0           0  \n",
            "2       0    0               0         0         0   0    0           0  \n",
            "3       0    0               0         0         0   0    0           0  \n",
            "4       0    0               0         0         0   1    0           0  \n",
            "\n",
            "[5 rows x 3002 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 3: Handle Missing Values (Imputation)**"
      ],
      "metadata": {
        "id": "hwXHaoQVYiVp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Impute missing values using mean imputation\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X)\n"
      ],
      "metadata": {
        "id": "UuM7VexMWsSy"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 4: Split the Data into Training and Testing Sets**"
      ],
      "metadata": {
        "id": "wwy0HY8IYnx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "zowMNMMEWu6C"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 5: Initialize and Train the Naive Bayes Classifier**"
      ],
      "metadata": {
        "id": "SerX_N1AYvnW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and train the Naive Bayes classifier\n",
        "classifier = MultinomialNB()\n",
        "classifier.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "p8N5HHqOWzFz",
        "outputId": "25f74ce4-7706-421e-d89e-f711416d1ddc"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 6: Make Predictions and Evaluate the Model**"
      ],
      "metadata": {
        "id": "npJqBzyZY4AD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test set\n",
        "predictions = classifier.predict(X_test)\n",
        "\n",
        "# Calculate accuracy and display results\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "\n",
        "# Display classification report\n",
        "print(classification_report(y_test, predictions))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4aquV6I8W0mP",
        "outputId": "d49aee5b-02db-46cd-adc1-47297ac5a15e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.95\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.95      0.97       739\n",
            "           1       0.89      0.96      0.92       296\n",
            "\n",
            "    accuracy                           0.95      1035\n",
            "   macro avg       0.94      0.96      0.95      1035\n",
            "weighted avg       0.96      0.95      0.96      1035\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "An accuracy score of 0.95 implies that the model correctly predicted 95% of the outcomes, which is a high level of accuracy."
      ],
      "metadata": {
        "id": "39DoBdDgh2am"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Conclusion\n",
        "\n",
        "In conclusion, this project marks a significant achievement in the realm of email filtering. With an accuracy score of 0.95, our spam email classifier demonstrated its proficiency in identifying unwanted emails, ensuring a cleaner and more efficient inbox experience. The precision, recall, and F1-score values provide a comprehensive understanding of the model's performance, underscoring its effectiveness in distinguishing between spam and non-spam emails. By leveraging advanced machine learning techniques, specifically the Multinomial Naive Bayes algorithm, I've created a powerful tool capable of accurately distinguishing between spam and legitimate messages."
      ],
      "metadata": {
        "id": "TxRgUq3FhBne"
      }
    }
  ]
}